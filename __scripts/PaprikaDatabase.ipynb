{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paprika Database\n",
    "\n",
    "This script connects to Paprika app's SQLite database and pull out whatever we want and format it as JSON, YAML, whatever.\n",
    "\n",
    "## NOTE:\n",
    "Before running the first time:\n",
    "1. create a file in the same directory as this Notebook, named \"config.py\"\n",
    "2. copy paste this line:\n",
    "\n",
    "path_project    = \"/local/path/to/this/repo/joi.github.io\"\n",
    "\n",
    "_(which should be the path to the direcotry one level up from where this file here is.)_\n",
    "\n",
    "3. pip install commonmark | NEW!\n",
    "4. pip install Unidecode | https://pypi.org/project/Unidecode/\n",
    "5. pip install pathvalidate | https://pypi.org/project/pathvalidate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS -------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import json\n",
    "import commonmark\n",
    "import pprint\n",
    "from pathvalidate import sanitize_filename\n",
    "import unidecode\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import config # This imports our local config file, \"config.py\". Access vars like so: config.var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARS -----------------------------------------\n",
    "\n",
    "# Date time stamp\n",
    "now = datetime.now()\n",
    "dt = now.strftime(\"%Y-%m-%d %H.%M\")\n",
    "#print(dt)\n",
    "\n",
    "# Environment-dependent Paths\n",
    "path_project    = config.path_project # manually set in config.py, which is NOT checked into GIT.\n",
    "path_user_home  = str(Path.home())    # automatically detects the User home directory path from the OS/ENV\n",
    "\n",
    "# Paprika Database Path\n",
    "filename_db     = 'Paprika.sqlite'\n",
    "path_paprika    = '/Library/Group Containers/72KVKW69K8.com.hindsightlabs.paprika.mac.v3/Data/'\n",
    "path_db_sub     = path_paprika + 'Database/'\n",
    "path_db_med     = path_user_home + path_db_sub\n",
    "path_db_full    = path_user_home + path_db_sub + filename_db\n",
    "path_photos     = path_user_home + path_paprika + 'Photos/'\n",
    "\n",
    "# Paprika Databse Backup. / We create this before we do anything, just in case.\n",
    "file_db_bu          = 'Paprika-BU-' + dt + '.sqlite'\n",
    "path_db_bu_sub      = path_project + '/__scripts/backups/'\n",
    "path_db_bu          = path_db_bu_sub + file_db_bu + '.zip'\n",
    "\n",
    "# Replaces Above \"Working\"\n",
    "path_temp_working   = path_db_bu_sub + \"tmp/\" # put tmp in backup\n",
    "path_db_working     = path_temp_working + filename_db\n",
    "\n",
    "# Output\n",
    "path_output_json_data = path_project + '/_data/'\n",
    "path_output_json_files = path_project + '/_data/recipes/'\n",
    "path_output_mkdn_files = path_project + '/_recipes/'\n",
    "path_output_phot_files = path_project + '/images/recipes/'\n",
    "\n",
    "# Paparika Timestamp Offset: 978307200\n",
    "ts_offset = 978307200\n",
    "\n",
    "\n",
    "# - FUNCTIONS ----------------------------------\n",
    "\n",
    "# Utility Functions ----------------------------\n",
    "\n",
    "# Clobber a string into a filename -------------\n",
    "def make_filename(string):\n",
    "    string = unidecode.unidecode(string)\n",
    "    # Need to strip out amperstands. See content.html liquid too.\n",
    "    string = string.replace(\" &\",\"\")\n",
    "    string = string.replace(\" \",\"-\")\n",
    "    #string = created[0:10] + \"-\" + string\n",
    "    #string=str(bytes(string, 'utf-8').decode('utf-8','ignore').encode(\"utf-8\",'ignore'))\n",
    "    #string=string.replace(\"b'\",\"\").replace(\"'\",\"\")\n",
    "    invalid = '<>:\"/\\|?* ,()“”‘’\\''\n",
    "    for char in invalid:\n",
    "        string = string.replace(char, '')\n",
    "    string = sanitize_filename(string)\n",
    "    \n",
    "    return string\n",
    "\n",
    "# Delete and Create Output Directories\n",
    "def output_directories(path):\n",
    "  if os.path.exists(path):\n",
    "    shutil.rmtree(path, ignore_errors=True)\n",
    "  os.mkdir(path)\n",
    "\n",
    " # Turn a multiline text block into a Markdown List\n",
    "def make_list(text):\n",
    "    return \"* \" + text.replace(\"\\n\", \"\\n* \") \n",
    "\n",
    "# Database Functions ---------------------------\n",
    "\n",
    "# Connect to Database\n",
    "def db_connect(db_file):\n",
    "    #conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        # row_factory does some magic for us\n",
    "        # see: https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query\n",
    "        conn.row_factory = sqlite3.Row\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "\n",
    "# Parse Paprika Markdown-ish into Markdown\n",
    "def paprika_markdownish(content,photos_dict):\n",
    "    r1 = []\n",
    "    if content:\n",
    "        r1 = re.findall(r\"\\[(photo|recipe):(.+?)\\]\",content,re.MULTILINE)\n",
    "        if r1:\n",
    "            for (key,value) in r1:\n",
    "                if key == 'recipe':\n",
    "                    new_txt = re.sub(r\"\\[recipe:(.+?)\\]\",\"(\" + value.strip() + \")[RECIPE URL]\",content)\n",
    "                    return new_txt\n",
    "                elif key == 'photo':\n",
    "                    try:\n",
    "                        print(photos_dict)\n",
    "                        print(r1)\n",
    "                        print(content)\n",
    "                        print('photo filename: ' + photos_dict[value.strip()])\n",
    "                        new_txt = re.sub(r\"\\[photo:(.+?)\\]\",\"![[\" + path_photos + photos_dict[value.strip()] + \"]]\",content)\n",
    "                        print(new_txt)\n",
    "                        return new_txt\n",
    "                    except:\n",
    "                        print('photo number: ' + value + ' not found')\n",
    "    # RegEx match any occurance of [chars] not preceded by \"!\" and not followed by \"(\" in {content}\n",
    "    # Explode the contents of the [] pair on \":\"\n",
    "    # if 0 == recipe -> pass 1 to make_filename()\n",
    "    # if 0 == photo -> take 1 as key into {photos_dict} and get filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT DESTINATIOn DIRECTORIES ---------------------\n",
    "\n",
    "# If Output Paths don't exist, create them\n",
    "if not os.path.exists(path_db_bu_sub):\n",
    "    os.mkdir(path_db_bu_sub)\n",
    "\n",
    "#if not os.path.exists(path_output_json_files):\n",
    "#    os.mkdir(path_output_json_files)\n",
    "#if not os.path.exists(path_output_mkdn_files):\n",
    "#    os.mkdir(path_output_mkdn_files)\n",
    "\n",
    "output_directories(path_output_json_files)\n",
    "output_directories(path_output_mkdn_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE BACKUPS -----------------------------------\n",
    "\n",
    "# Make a zipped backup of the DB\n",
    "zipfile.ZipFile(path_db_bu, mode='w').write(path_db_full, arcname=file_db_bu, compress_type=zipfile.ZIP_DEFLATED, compresslevel=9)\n",
    "\n",
    "\n",
    "# Make a temp copy of the DB to work with. We delete it later.\n",
    "#\n",
    "# First, check if the temp folder already exists and if so delete it\n",
    "if os.path.exists(path_temp_working):\n",
    "    shutil.rmtree(path_temp_working, ignore_errors=True) #nuke the temp working dir.\n",
    "\n",
    "copy_DB_Return = shutil.copytree(path_db_med, path_temp_working) # create a var here just to capture the useless out put of the copyfile() function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE OPERATIONS ------------------------------\n",
    "\n",
    "# First Database Operation: WAL Checkpoint\n",
    "conn = db_connect(path_db_working)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"PRAGMA wal_checkpoint;\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{}\n",
      "[('photo', '2')]\n",
      "photo number: 2 not found\n",
      "* 4 chunks monkfish fillet, about 6 ounces each, skin and translucent membrane removed\n",
      "* Salt\n",
      "* 1/2 cup mild-tasting olive oil\n",
      "* 1 medium fennel bulb, trimmed and cut into 1/2-inch-thick wedges (about 8 ounces)\n",
      "* 3/4 cup diced yellow onions (3 ounces)\n",
      "* 1/2 cup dry white wine\n",
      "* 6 ounces very ripe tomatoes, peeled, cored (1 large or 2 small), cut into wedges, and lightly salted, or 3/4 cup drained canned tomatoes, quartered\n",
      "* A few garlic cloves, coarsely chopped\n",
      "* 1 small dried chili or a pinch of dried chili flakes\n",
      "* A pinch of saffron threads\n",
      "* A splash of pastis, such as Pernod or Ricard, or ouzo\n",
      "* About 1 cup Monkfish Fumet or (Chicken Stock)[RECIPE URL]\n",
      "* About 1-1/2 cups cooked white beans, drained, cooking liquid reserved\n",
      "* About 1/2 cup (Chicken Stock)[RECIPE URL]\n",
      "* 1. chicken legs (about 8 ounces each) or one 3-pound chicken, back removed\n",
      "* 2. and quartered\n",
      "* 3. ounces sliced yellow onion {2 cups, about 1 medium onion}\n",
      "* 4. /4 cup extra-virgin olive oil\n",
      "* 5. Salt\n",
      "* 6. bay leaf\n",
      "* 7. A sprig of fresh thyme\n",
      "* 8. small dried chili\n",
      "* 9. /4 cup dry white wine\n",
      "* 10. /4 cup coarsely chopped drained canned tomatoes or 1/3 cup chopped, peeled,\n",
      "* 11. ripe tomatoes\n",
      "* 12. Pinch of saffron threads\n",
      "* 13. garlic cloves, coarsely chopped\n",
      "* 14. cups (Chicken Stock)[RECIPE URL]\n",
      "* 15. small slices chewy peasant-style bread, about 1/2 inch thick\n",
      "* 16. About 1/2 cup (Chicken Stock)[RECIPE URL] or 1 garlic clove, peeled\n",
      "{'1': 'A11F7F03-B770-4019-9A26-AF1B2931D454-4181-0001E276D00B9041.jpg'}\n",
      "[('photo', '2')]\n",
      "photo number: 2 not found\n",
      "* **For the chicken marinade:**\n",
      "* Whole chicken\n",
      "* 1 cup plain yogurt\n",
      "* 1 1/2 tablespoons minced garlic\n",
      "* 1 tablespoon ginger\n",
      "* 2 teaspoons (Garam Masala)[RECIPE URL]\n",
      "* 1 teaspoon turmeric\n",
      "* 1 teaspoon ground cumin\n",
      "* 1 teaspoon Kashmiri chili (or 1/2 teaspoon ground red chili powder)\n",
      "* 1 teaspoon of salt\n",
      "* **For the sauce:**\n",
      "* 2 tablespoons of vegetable/canola oil\n",
      "* 2 tablespoons butter\n",
      "* 2 small onions (or 1 large onion) finely diced\n",
      "* 1 1/2 tablespoons garlic finely grated\n",
      "* 1 tablespoon ginger finely grated\n",
      "* 1 1/2 teaspoons garam masala\n",
      "* 1 1/2 teaspoons ground cumin\n",
      "* 1 teaspoon turmeric powder\n",
      "* 1 teaspoon ground coriander\n",
      "* 14 oz (400g) tomato puree (tomato sauce/Passata)\n",
      "* 1 teaspoon Kashmiri chili (optional for color and flavor)\n",
      "* 1 teaspoon ground red chili powder (adjust to your taste preference)\n",
      "* 1 teaspoon salt\n",
      "* 1 1/4 cups of heavy or thickened cream (use evaporated milk for lower calories)\n",
      "* 1 teaspoon brown sugar\n",
      "* 1/4 cup water if needed\n",
      "* 4 tablespoons Fresh cilantro to garnish\n",
      "* ⅔ cup of fresh (Mayonnaise)[RECIPE URL]\n",
      "* 1 tbsp ketchup\n",
      "* 1 tsp Worcestershire sauce\n",
      "* 1 tsp freshly grated horseradish or wasabi\n",
      "* Tabasco sauce\n",
      "* Pinch of paprika\n",
      "{'13': 'AF5A63AD-A6A7-4120-8632-FBF6D915A5FF-15291-00020AEBB089BAC2.jpg', '4': '6C3FB3CC-8DD5-475E-B6B8-E984E25CD7BF-15291-00020AB48718098A.jpg', '12': 'AD78167B-A996-4767-8B49-5958EFB99ED0-15291-00020AEB3104FAEA.jpg', '5': 'A034FC50-3415-4B00-B5BB-573BC5153AAC-15291-00020AB4871D98CC.jpg', '3': 'D43CBEA3-B1DF-453D-A9A3-CB1E12C0E41D-15291-00020AB487129F4C.jpg', '9': '9662101C-1BA4-450F-B8A4-ADB4388F077C-15291-00020AE981F5F05C.jpg', '10': '4C9E2748-A53D-4114-876A-BD0D73EE5170-15291-00020AEA4196A657.jpg', '8': '3CE47A78-B331-444E-9991-129C0DEE3D5E-15291-00020AE8106343B7.jpg', '7': 'C3DE8BB3-8B89-44B7-8D55-A40AC1CEE967-15291-00020AE7AAD11CED.jpg', '6': 'B3009C8F-3EBC-4E8C-8B0A-3B9D6778662F-15291-00020AE6E8348173.jpg', '11': 'A5CD9902-A91A-499C-A8C0-07201C1C17AA-15291-00020AEAC66185AE.jpg'}\n",
      "[('photo', '2')]\n",
      "photo number: 2 not found\n"
     ]
    }
   ],
   "source": [
    "# Second Database Operation: Get our recipe Data\n",
    "conn = db_connect(path_db_working)\n",
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"\"\"\n",
    "SELECT \n",
    "    GROUP_CONCAT(C.ZNAME,\"|\") as `categories`,\n",
    "    R.ZCOOKTIME        as `cook_time`,\n",
    "    R.ZINTRASH        as `intrash`,\n",
    "    datetime(R.ZCREATED + {ts_offset},'unixepoch') as `created`,\n",
    "    R.ZCREATED + {ts_offset}                       as `created_ts`,\n",
    "    R.ZDESCRIPTIONTEXT as `description`,\n",
    "    R.ZDIFFICULTY      as `difficulty`,\n",
    "    R.ZDIRECTIONS      as `directions`,\n",
    "    R.ZINGREDIENTS     as `ingredients`,\n",
    "    R.ZIMAGEURL        as `image_url`,\n",
    "    R.ZNAME            as `name`,\n",
    "    R.ZNOTES           as `notes`,\n",
    "    R.ZNUTRITIONALINFO as `nutritional_info`,\n",
    "    R.ZPHOTO           as `photo`,\n",
    "    R.ZPHOTOLARGE      as `photo_large`,\n",
    "    R.ZPREPTIME        as `prep_time`,\n",
    "    R.ZRATING          as `rating`,\n",
    "    R.ZSERVINGS        as `servings`,\n",
    "    R.ZSOURCE          as `source`,\n",
    "    R.ZSOURCEURL       as `source_url`,\n",
    "    R.ZTOTALTIME       as `total_time`,\n",
    "    R.ZUID             as `uid`,\n",
    "    -- We need to do these SELECTS because\n",
    "    -- otherwise the Category concat\n",
    "    -- replicates itself the number of times\n",
    "    -- there are images. No idea why.\n",
    "    (\n",
    "        SELECT\n",
    "            GROUP_CONCAT(RP.ZFILENAME,\"|\") as filename\n",
    "        FROM\n",
    "            ZRECIPEPHOTO as RP\n",
    "        WHERE\n",
    "            RP.ZRECIPE = R.Z_PK\n",
    "    ) as photos_filenames,\n",
    "    (\n",
    "        SELECT\n",
    "            GROUP_CONCAT(RP.ZNAME,\"|\") as name\n",
    "        FROM\n",
    "            ZRECIPEPHOTO as RP\n",
    "        WHERE\n",
    "            RP.ZRECIPE = R.Z_PK\n",
    "    ) as photos_names\n",
    "\n",
    "FROM\n",
    "    ZRECIPE as R\n",
    "\n",
    "LEFT JOIN    Z_12CATEGORIES AS RC\n",
    "    ON    RC.Z_12RECIPES = R.Z_PK\n",
    "LEFT JOIN    ZRECIPECATEGORY AS C\n",
    "    ON    RC.Z_13CATEGORIES = C.Z_PK\n",
    "\n",
    "WHERE R.ZINTRASH IS 0\n",
    "GROUP BY    R.Z_PK;\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    \n",
    "# --------------------------------------------------------------------------------------\n",
    "# For the next bit with columns and results and dict and zip, see:\n",
    "#    https://stackoverflow.com/questions/16519385/output-pyodbc-cursor-results-as-python-dictionary/16523148#16523148\n",
    "#\n",
    "\n",
    "# This grabs the key (cur.descriptiomn) for us\n",
    "columns = [column[0] for column in cur.description]\n",
    "rows = cur.fetchall()\n",
    "counter = 0\n",
    "counter2 = 0\n",
    "\n",
    "results = []\n",
    "for row in rows:\n",
    "    # and here we glue the key to the value\n",
    "    results.append(dict(zip(columns, row)))\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# Create a dict to hold the cats -> recipes dictionary\n",
    "cats = {}\n",
    "\n",
    "for result in results:\n",
    "    result['photos_dict'] = {}\n",
    "    result['photos'] = []\n",
    "    result['html'] = {}\n",
    "    result['type'] = None\n",
    "\n",
    "    # FILENAME : This is our Key between the YAML in Markdown stubs and the JSON Data files\n",
    "    fileName = make_filename(result['name'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # Start of RESULT Items FOR loop {\n",
    "    for key,value in result.items():\n",
    "        # ---------------------------------------------------\n",
    "        # Photos Stuff\n",
    "        # We do this first so we have access to the photo data when parsing Paprika Markdown-ish [photo:name]\n",
    "        # Split concatened photo filenames and names into a lists\n",
    "        if key == \"photos_filenames\":\n",
    "            try:\n",
    "                result['photos_filenames'] = value.split('|')\n",
    "            except:\n",
    "                pass\n",
    "        if key == \"photos_names\":\n",
    "            try:\n",
    "                result['photos_names'] = value.split('|')\n",
    "                # if we have photo_names, zip filenames & names into into a key=value dict\n",
    "                # We will use this for the PMD parse below\n",
    "                result['photos_dict'] = dict(zip(result['photos_names'], result['photos_filenames']))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        #if result[\"photos\"] == []:\n",
    "        #    result[\"photos\"] = False \n",
    "\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # Directions, Descriptions, Ingredients, Nutritional Info\n",
    "    if result['directions']:\n",
    "      #rdirections  = paprika_markdownish(str(result['directions']),result['photos_dict'])\n",
    "      #rdirections  = commonmark.commonmark(str(rdirections))\n",
    "      rdirections  = paprika_markdownish(rdirections,result['photos_dict'])\n",
    "      rdirections  = commonmark.commonmark(str(result['directions']))\n",
    "    else:\n",
    "      rdirections = None\n",
    "\n",
    "    if result['description']:\n",
    "      rdescription = paprika_markdownish(rdescription,result['photos_dict'])\n",
    "      rdescription = commonmark.commonmark(str(result['description']))\n",
    "    else:\n",
    "      rdescription = None\n",
    "\n",
    "    if result['ingredients']:\n",
    "      list_ing_lines   = paprika_markdownish(list_ing_lines,result['photos_dict'])\n",
    "      list_ing_lines   = re.sub('\\\\\\\\x{0D}','\\n',str(result['ingredients']))\n",
    "      list_ing_lines   = re.sub('\\n\\n','\\n',list_ing_lines)\n",
    "      list_ing_lines   = make_list(list_ing_lines)\n",
    "      ringredients = commonmark.commonmark(str(list_ing_lines))\n",
    "    else:\n",
    "      ringredients = None\n",
    "\n",
    "    if result['nutritional_info']:\n",
    "      rnutrition = commonmark.commonmark(str(result['nutritional_info']))\n",
    "    else:\n",
    "      rnutrition = None\n",
    "\n",
    "    result['html'] = {\n",
    "      'directions'  : rdirections,\n",
    "      'description' : rdescription,\n",
    "      'ingredients' : ringredients,\n",
    "      'nutrition'   : rnutrition\n",
    "      }\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Categories\n",
    "    # Split concatened categories into a list\n",
    "    if key == \"categories\":\n",
    "        try:\n",
    "            result['categories'] = value.split('|')\n",
    "            for cl in result['categories']:\n",
    "              #catss = {make_filename(result['name']):str(result['name']}\n",
    "              #catss_copy = catss.copy()\n",
    "              #cats[ck].append(catss_copy)\n",
    "              #cats[ck][make_filename(result['name'])] = str(result['name'])\n",
    "              \n",
    "              # Using the categories as a toggle hack (by Joi or not)\n",
    "              if cl == \"_mine\":\n",
    "                result['type'] = cl\n",
    "\n",
    "              if cl not in cats.keys():\n",
    "                cats[cl] = {}\n",
    "\n",
    "              if fileName not in cats[cl].keys():\n",
    "                cats[cl][fileName] = str(result['name'])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Sources\n",
    "    if result[\"source\"] == \"\":\n",
    "        result[\"source\"] = None \n",
    "    if result[\"source_url\"] == \"\":\n",
    "        result[\"source_url\"] = None \n",
    "\n",
    "    # end of RESULT Items FOR loop }\n",
    "    # --------------------------------------------------------------------------------------\n",
    "  \n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # Temporary, parse out the name:filename dictionary into a list of key:value dicts\n",
    "    # I am doing this to preserve legacy in the Jekyl templates. May remove laters.\n",
    "    for k,v in sorted(result['photos_dict'].items()):\n",
    "        phots = {'filename':v,'name':k}\n",
    "        result['photos'].append(phots)\n",
    "    # Delete the concatened phot_names and photo_filenames string we got from the SQL query\n",
    "    del result['photos_names'],result['photos_filenames']\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    # Convert the data struct to JSON and dump it to individual files\n",
    "    json_dump = json.dumps(result, ensure_ascii=False, sort_keys=True, indent=2)\n",
    "    jsonFilePath = path_output_json_files + fileName + \".json\"\n",
    "    f = open(jsonFilePath, 'w')\n",
    "    f.write(json_dump)\n",
    "    f.close()\n",
    "\n",
    "    # Prepare and Dump the Markodwn Recipe Stub Files\n",
    "    # MARKDOWN --------------------------------\n",
    "    # Create a string of Markdown\n",
    "    # So this will require some \"design.\" What do we want to include from the export?\n",
    "    # How should it be styled? What do we jam into the metadata/frontmatter\n",
    "    # What do we include as #tags in the body?\n",
    "\n",
    "    output  = \"---\\n\"\n",
    "    output += \"title: \\\"\" + result['name'] + \"\\\"\\n\"\n",
    "    output += \"filename: \\\"\" + fileName + \"\\\"\\n\"\n",
    "    output += \"created: \" + str(result['created']) + \"\\n\"\n",
    "    output += \"---\\n\"\n",
    "    if (result['notes']):\n",
    "      output += str(result['notes']) + \"\\n\"\n",
    "    \n",
    "    # Create/Open a text file for each recipe and write the above Markdown string into it\n",
    "    mdFilePath = path_output_mkdn_files + fileName + \".md\"\n",
    "    f = open(mdFilePath, 'w')\n",
    "    f.write(output)\n",
    "    f.close()\n",
    "    \n",
    "# CLOSE DB\n",
    "conn.close()\n",
    "\n",
    "\n",
    "# Convert the data struct to JSON and dump it to individual files\n",
    "json_cats_dump = json.dumps(cats, ensure_ascii=False, sort_keys=True, indent=2)\n",
    "jsonDataPath = path_output_json_data + \"recipe_categories.json\"\n",
    "f = open(jsonDataPath, 'w')\n",
    "f.write(json_cats_dump)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# End of Main RESULTS FOR Loop }\n",
    "    \n",
    "#pp = pprint.PrettyPrinter(indent=4)\n",
    "#pp.pprint(cats)\n",
    "#print(cats)\n",
    "\n",
    "# CLEANUP --------------------------------------------\n",
    "# Delete the temp working direcotry\n",
    "shutil.rmtree(path_temp_working, ignore_errors=True) # \"ignore errors\" nukes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES ----------------------------------------------\n",
    "# Move the images out of the unzipped My Recipes dir to somehwere Jekyll can pick them up.\n",
    "\n",
    "if os.path.exists(path_output_phot_files):\n",
    "    shutil.rmtree(path_output_phot_files, ignore_errors=True)\n",
    "    #print(\"Nuked Recipe / Images Directory\")\n",
    "\n",
    "moveReturn = shutil.copytree(path_photos, path_output_phot_files)\n",
    "#print(\"Successfully copied to destination path:\", moveReturn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DONE!\n",
    "👍🏼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}