{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paprika Database\n",
    "\n",
    "This script connects to Paprika app's SQLite database and pull out whatever we want and format it as JSON, YAML, whatever.\n",
    "\n",
    "## NOTE:\n",
    "Before running the first time:\n",
    "1. create a file in the same directory as this Notebook, named \"config.py\"\n",
    "2. copy paste this line:\n",
    "\n",
    "path_project    = \"/local/path/to/this/repo/joi.github.io\"\n",
    "\n",
    "_(which should be the path to the direcotry one level up from where this file here is.)_\n",
    "\n",
    "3. pip install commonmark | NEW!\n",
    "4. pip install Unidecode | https://pypi.org/project/Unidecode/\n",
    "5. pip install pathvalidate | https://pypi.org/project/pathvalidate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS -------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import json\n",
    "import commonmark\n",
    "import pprint\n",
    "from pathvalidate import sanitize_filename\n",
    "import unidecode\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import config # This imports our local config file, \"config.py\". Access vars like so: config.var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARS -----------------------------------------\n",
    "\n",
    "# Date time stamp\n",
    "now = datetime.now()\n",
    "dt = now.strftime(\"%Y-%m-%d %H.%M\")\n",
    "#print(dt)\n",
    "\n",
    "# Environment-dependent Paths\n",
    "path_project    = config.path_project # manually set in config.py, which is NOT checked into GIT.\n",
    "path_user_home  = str(Path.home())    # automatically detects the User home directory path from the OS/ENV\n",
    "\n",
    "# Paprika Database Path\n",
    "filename_db     = 'Paprika.sqlite'\n",
    "path_paprika    = '/Library/Group Containers/72KVKW69K8.com.hindsightlabs.paprika.mac.v3/Data/'\n",
    "path_db_sub     = path_paprika + 'Database/'\n",
    "path_db_med     = path_user_home + path_db_sub\n",
    "path_db_full    = path_user_home + path_db_sub + filename_db\n",
    "path_photos     = path_user_home + path_paprika + 'Photos/'\n",
    "\n",
    "# Paprika Databse Backup. / We create this before we do anything, just in case.\n",
    "file_db_bu          = 'Paprika-BU-' + dt + '.sqlite'\n",
    "path_db_bu_sub      = path_project + '/__scripts/backups/'\n",
    "path_db_bu          = path_db_bu_sub + file_db_bu + '.zip'\n",
    "\n",
    "# Replaces Above \"Working\"\n",
    "path_temp_working   = path_db_bu_sub + \"tmp/\" # put tmp in backup\n",
    "path_db_working     = path_temp_working + filename_db\n",
    "\n",
    "# Output\n",
    "path_output_json_data = path_project + '/_data/'\n",
    "path_output_json_files = path_project + '/_data/recipes/'\n",
    "path_output_mkdn_files = path_project + '/_recipes/'\n",
    "path_output_phot_files = path_project + '/images/recipes/'\n",
    "\n",
    "# Paparika Timestamp Offset: 978307200\n",
    "ts_offset = 978307200\n",
    "\n",
    "\n",
    "# - FUNCTIONS ----------------------------------\n",
    "\n",
    "# Utility Functions ----------------------------\n",
    "\n",
    "# Clobber a string into a filename -------------\n",
    "def make_filename(string):\n",
    "    string = unidecode.unidecode(string)\n",
    "    # Need to strip out amperstands. See content.html liquid too.\n",
    "    string = string.replace(\" &\",\"\")\n",
    "    string = string.replace(\" \",\"-\")\n",
    "    #string = created[0:10] + \"-\" + string\n",
    "    #string=str(bytes(string, 'utf-8').decode('utf-8','ignore').encode(\"utf-8\",'ignore'))\n",
    "    #string=string.replace(\"b'\",\"\").replace(\"'\",\"\")\n",
    "    invalid = '<>:\"/\\|?* ,()“”‘’\\''\n",
    "    for char in invalid:\n",
    "        string = string.replace(char, '')\n",
    "    string = sanitize_filename(string)\n",
    "    \n",
    "    return string\n",
    "\n",
    "# Delete and Create Output Directories\n",
    "def output_directories(path):\n",
    "  if os.path.exists(path):\n",
    "    shutil.rmtree(path, ignore_errors=True)\n",
    "  os.mkdir(path)\n",
    "\n",
    " # Turn a multiline text block into a Markdown List\n",
    "def make_list(text):\n",
    "    return \"* \" + text.replace(\"\\n\", \"\\n* \") \n",
    "\n",
    "# Database Functions ---------------------------\n",
    "\n",
    "# Connect to Database\n",
    "def db_connect(db_file):\n",
    "    #conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        # row_factory does some magic for us\n",
    "        # see: https://stackoverflow.com/questions/3300464/how-can-i-get-dict-from-sqlite-query\n",
    "        conn.row_factory = sqlite3.Row\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "\n",
    "# Parse Paprika Markdown-ish into Markdown\n",
    "def paprika_markdownish(content,photos_dict):\n",
    "    r1 = []\n",
    "    if content:\n",
    "        r1 = re.findall(r\"\\[(photo|recipe):(.+?)\\]\",content,re.MULTILINE)\n",
    "        if r1:\n",
    "            for (key,value) in r1:\n",
    "                if key == 'recipe':\n",
    "                    new_txt = re.sub(r\"\\[recipe:(.+?)\\]\",\"(\" + value.strip() + \")[RECIPE URL]\",content)\n",
    "                    return new_txt\n",
    "                elif key == 'photo':\n",
    "                    try:\n",
    "                        print(photos_dict)\n",
    "                        print(r1)\n",
    "                        print(content)\n",
    "                        print('photo filename: ' + photos_dict[value.strip()])\n",
    "                        new_txt = re.sub(r\"\\[photo:(.+?)\\]\",\"![[\" + path_photos + photos_dict[value.strip()] + \"]]\",content)\n",
    "                        print(new_txt)\n",
    "                        return new_txt\n",
    "                    except:\n",
    "                        print('photo number: ' + value + ' not found')\n",
    "    # RegEx match any occurance of [chars] not preceded by \"!\" and not followed by \"(\" in {content}\n",
    "    # Explode the contents of the [] pair on \":\"\n",
    "    # if 0 == recipe -> pass 1 to make_filename()\n",
    "    # if 0 == photo -> take 1 as key into {photos_dict} and get filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT DESTINATIOn DIRECTORIES ---------------------\n",
    "\n",
    "# If Output Paths don't exist, create them\n",
    "if not os.path.exists(path_db_bu_sub):\n",
    "    os.mkdir(path_db_bu_sub)\n",
    "\n",
    "#if not os.path.exists(path_output_json_files):\n",
    "#    os.mkdir(path_output_json_files)\n",
    "#if not os.path.exists(path_output_mkdn_files):\n",
    "#    os.mkdir(path_output_mkdn_files)\n",
    "\n",
    "output_directories(path_output_json_files)\n",
    "output_directories(path_output_mkdn_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE BACKUPS -----------------------------------\n",
    "\n",
    "# Make a zipped backup of the DB\n",
    "zipfile.ZipFile(path_db_bu, mode='w').write(path_db_full, arcname=file_db_bu, compress_type=zipfile.ZIP_DEFLATED, compresslevel=9)\n",
    "\n",
    "\n",
    "# Make a temp copy of the DB to work with. We delete it later.\n",
    "#\n",
    "# First, check if the temp folder already exists and if so delete it\n",
    "if os.path.exists(path_temp_working):\n",
    "    shutil.rmtree(path_temp_working, ignore_errors=True) #nuke the temp working dir.\n",
    "\n",
    "copy_DB_Return = shutil.copytree(path_db_med, path_temp_working) # create a var here just to capture the useless out put of the copyfile() function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE OPERATIONS ------------------------------\n",
    "\n",
    "# First Database Operation: WAL Checkpoint\n",
    "conn = db_connect(path_db_working)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"PRAGMA wal_checkpoint;\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{}\n",
      "[('photo', '2')]\n",
      "<p>Works well in a wok but you can use any sauté pan.</p>\n",
      "<p>Fry tofu and set aside. Remove all but 2 tbsp of oil from wok.</p>\n",
      "<p>[photo:2]</p>\n",
      "<p>Chop the onion, garlic and tomato and put in a bowl or vat. Chop the bok choy and shrimp and put in another bowl or vat.</p>\n",
      "<p>Heat pan slowly if you have time so that the whole pan gets hot and can hold the heat through the stir fry.</p>\n",
      "<p>Add oil to pan and add onion, garlic and tomato and sauté.</p>\n",
      "<p>Add tofu and bok choy and stir-fry for 3 - 5 min until the bok choy is tender, but not soft. If you want, you can separate the leafy part from the thick stems and add them a min or two after the thick parts.</p>\n",
      "<p>Add chicken broth (or water if you don't have any) and bring to boil. Cover and simmer for 2 - 3 min.</p>\n",
      "<p>Add fish sauce and ground black pepper.</p>\n",
      "\n",
      "photo number: 2 not found\n",
      "{'1': 'A11F7F03-B770-4019-9A26-AF1B2931D454-4181-0001E276D00B9041.jpg'}\n",
      "[('photo', '2')]\n",
      "<p>Break down chicken into 10 parts - drum stick, thighs, breast into 4 parts, wings. Save the back and wing tips for stock.</p>\n",
      "<p>[photo:2]</p>\n",
      "<p>In a bowl, combine chicken with all of the ingredients for the chicken marinade; let marinate overnight.</p>\n",
      "<p>Preheat oven to 300ºF.</p>\n",
      "<p>Heat oil in a large skillet or pot over medium-high heat and sear chicken pieces. 3 or 4 min per side. Do in batches and do not crowd.</p>\n",
      "<p>Melt butter in pan and sauté onions until soft.</p>\n",
      "<p>Add garlic and ginger and sauté for 1 minute until fragrant, then add garam masala, cumin, turmeric and coriander. Fry for 20 seconds until fragrant.</p>\n",
      "<p>Pour in the tomato puree, chili and salt. Let simmer for about 10-15 minutes, stirring occasionally until sauce thickens.</p>\n",
      "<p>Stir in cream and sugar. Pour in the water to thin out the sauce, if needed.</p>\n",
      "<p>Put thighs and drumsticks in skin side up and bring to simmer. Cover and cook for 8 minutes. Add broad big pieces skin side down. Cover and cook until big breast pieces have an internal temperature of 105ºF to 115ºF degrees, 3 to 5 minutes.</p>\n",
      "<p>Turn big breast pieces skin side up. Add smaller tapered breast pieces, skin side up. Transfer covered pot to oven or simmer and cook until breast pieces have an internal temperature of 150ºF and dark meat is 160ºF, 15 to 30 minutes.</p>\n",
      "<p>Garnish with cilantro and serve.</p>\n",
      "\n",
      "photo number: 2 not found\n",
      "{'13': 'AF5A63AD-A6A7-4120-8632-FBF6D915A5FF-15291-00020AEBB089BAC2.jpg', '4': '6C3FB3CC-8DD5-475E-B6B8-E984E25CD7BF-15291-00020AB48718098A.jpg', '12': 'AD78167B-A996-4767-8B49-5958EFB99ED0-15291-00020AEB3104FAEA.jpg', '5': 'A034FC50-3415-4B00-B5BB-573BC5153AAC-15291-00020AB4871D98CC.jpg', '3': 'D43CBEA3-B1DF-453D-A9A3-CB1E12C0E41D-15291-00020AB487129F4C.jpg', '9': '9662101C-1BA4-450F-B8A4-ADB4388F077C-15291-00020AE981F5F05C.jpg', '10': '4C9E2748-A53D-4114-876A-BD0D73EE5170-15291-00020AEA4196A657.jpg', '8': '3CE47A78-B331-444E-9991-129C0DEE3D5E-15291-00020AE8106343B7.jpg', '7': 'C3DE8BB3-8B89-44B7-8D55-A40AC1CEE967-15291-00020AE7AAD11CED.jpg', '6': 'B3009C8F-3EBC-4E8C-8B0A-3B9D6778662F-15291-00020AE6E8348173.jpg', '11': 'A5CD9902-A91A-499C-A8C0-07201C1C17AA-15291-00020AEAC66185AE.jpg'}\n",
      "[('photo', '2')]\n",
      "<p>Works well in a wok but you can use any sauté pan.</p>\n",
      "<p>[photo:2]</p>\n",
      "<p>Chop the onion, garlic and tomato and put in a bowl or vat. Chop the bok choy and shrimp and put in another bowl or vat.</p>\n",
      "<p>Heat pan slowly if you have time so that the whole pan gets hot and can hold the heat through the stir fry.</p>\n",
      "<p>Add oil to pan and add onion, garlic and tomato and sauté.</p>\n",
      "<p>Add ground beef and sauté until brown.</p>\n",
      "<p>Add shrimp and bok choy and stir-fry for 3 - 5 min until the bok choy is tender, but not soft. If you want, you can separate the leafy part from the thick stems and add them a min or two after the thick parts.</p>\n",
      "<p>Add chicken broth (or water if you don't have any) and bring to boil. Cover and simmer for 2 - 3 min.</p>\n",
      "<p>Add fish sauce and ground black pepper.</p>\n",
      "\n",
      "photo number: 2 not found\n"
     ]
    }
   ],
   "source": [
    "# Second Database Operation: Get our recipe Data\n",
    "conn = db_connect(path_db_working)\n",
    "with conn:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"\"\"\n",
    "SELECT \n",
    "    GROUP_CONCAT(C.ZNAME,\"|\") as `categories`,\n",
    "    R.ZCOOKTIME        as `cook_time`,\n",
    "    R.ZINTRASH        as `intrash`,\n",
    "    datetime(R.ZCREATED + {ts_offset},'unixepoch') as `created`,\n",
    "    R.ZCREATED + {ts_offset}                       as `created_ts`,\n",
    "    R.ZDESCRIPTIONTEXT as `description`,\n",
    "    R.ZDIFFICULTY      as `difficulty`,\n",
    "    R.ZDIRECTIONS      as `directions`,\n",
    "    R.ZINGREDIENTS     as `ingredients`,\n",
    "    R.ZIMAGEURL        as `image_url`,\n",
    "    R.ZNAME            as `name`,\n",
    "    R.ZNOTES           as `notes`,\n",
    "    R.ZNUTRITIONALINFO as `nutritional_info`,\n",
    "    R.ZPHOTO           as `photo`,\n",
    "    R.ZPHOTOLARGE      as `photo_large`,\n",
    "    R.ZPREPTIME        as `prep_time`,\n",
    "    R.ZRATING          as `rating`,\n",
    "    R.ZSERVINGS        as `servings`,\n",
    "    R.ZSOURCE          as `source`,\n",
    "    R.ZSOURCEURL       as `source_url`,\n",
    "    R.ZTOTALTIME       as `total_time`,\n",
    "    R.ZUID             as `uid`,\n",
    "    -- We need to do these SELECTS because\n",
    "    -- otherwise the Category concat\n",
    "    -- replicates itself the number of times\n",
    "    -- there are images. No idea why.\n",
    "    (\n",
    "        SELECT\n",
    "            GROUP_CONCAT(RP.ZFILENAME,\"|\") as filename\n",
    "        FROM\n",
    "            ZRECIPEPHOTO as RP\n",
    "        WHERE\n",
    "            RP.ZRECIPE = R.Z_PK\n",
    "    ) as photos_filenames,\n",
    "    (\n",
    "        SELECT\n",
    "            GROUP_CONCAT(RP.ZNAME,\"|\") as name\n",
    "        FROM\n",
    "            ZRECIPEPHOTO as RP\n",
    "        WHERE\n",
    "            RP.ZRECIPE = R.Z_PK\n",
    "    ) as photos_names\n",
    "\n",
    "FROM\n",
    "    ZRECIPE as R\n",
    "\n",
    "LEFT JOIN    Z_12CATEGORIES AS RC\n",
    "    ON    RC.Z_12RECIPES = R.Z_PK\n",
    "LEFT JOIN    ZRECIPECATEGORY AS C\n",
    "    ON    RC.Z_13CATEGORIES = C.Z_PK\n",
    "\n",
    "WHERE R.ZINTRASH IS 0\n",
    "GROUP BY    R.Z_PK;\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    \n",
    "# --------------------------------------------------------------------------------------\n",
    "# For the next bit with columns and results and dict and zip, see:\n",
    "#    https://stackoverflow.com/questions/16519385/output-pyodbc-cursor-results-as-python-dictionary/16523148#16523148\n",
    "#\n",
    "\n",
    "# This grabs the key (cur.descriptiomn) for us\n",
    "columns = [column[0] for column in cur.description]\n",
    "rows = cur.fetchall()\n",
    "counter = 0\n",
    "counter2 = 0\n",
    "\n",
    "results = []\n",
    "for row in rows:\n",
    "    # and here we glue the key to the value\n",
    "    results.append(dict(zip(columns, row)))\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# Create a dict to hold the cats -> recipes dictionary\n",
    "cats = {}\n",
    "\n",
    "for result in results:\n",
    "    result['photos_dict'] = {}\n",
    "    result['photos'] = []\n",
    "    result['html'] = {}\n",
    "    result['type'] = None\n",
    "\n",
    "    # FILENAME : This is our Key between the YAML in Markdown stubs and the JSON Data files\n",
    "    fileName = make_filename(result['name'])\n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # Start of RESULT Items FOR loop {\n",
    "        # ---------------------------------------------------\n",
    "        # Photos Stuff\n",
    "        # We do this first so we have access to the photo data when parsing Paprika Markdown-ish [photo:name]\n",
    "        # Split concatened photo filenames and names into a lists\n",
    "    try:\n",
    "        result['photos_filenames'] = result['photos_filenames'].split('|')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        result['photos_names'] = result['photos_names'].split('|')\n",
    "        # if we have photo_names, zip filenames & names into into a key=value dict\n",
    "        # We will use this for the PMD parse below\n",
    "        \n",
    "        result['photos_dict'] = dict(zip(result['photos_names'], result['photos_filenames']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        #if result[\"photos\"] == []:\n",
    "        #    result[\"photos\"] = False \n",
    "\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # Directions, Descriptions, Ingredients, Nutritional Info\n",
    "    if result['directions']:\n",
    "      #rdirections  = paprika_markdownish(str(result['directions']),result['photos_dict'])\n",
    "      #rdirections  = commonmark.commonmark(str(rdirections))\n",
    "      rdirections  = paprika_markdownish(rdirections,result['photos_dict'])\n",
    "      rdirections  = commonmark.commonmark(str(result['directions']))\n",
    "    else:\n",
    "      rdirections = None\n",
    "\n",
    "    if result['description']:\n",
    "      rdescription = paprika_markdownish(rdescription,result['photos_dict'])\n",
    "      rdescription = commonmark.commonmark(str(result['description']))\n",
    "    else:\n",
    "      rdescription = None\n",
    "\n",
    "    if result['ingredients']:\n",
    "      list_ing_lines   = paprika_markdownish(list_ing_lines,result['photos_dict'])\n",
    "      list_ing_lines   = re.sub('\\\\\\\\x{0D}','\\n',str(result['ingredients']))\n",
    "      list_ing_lines   = re.sub('\\n\\n','\\n',list_ing_lines)\n",
    "      list_ing_lines   = make_list(list_ing_lines)\n",
    "      ringredients = commonmark.commonmark(str(list_ing_lines))\n",
    "    else:\n",
    "      ringredients = None\n",
    "\n",
    "    if result['nutritional_info']:\n",
    "      rnutrition = commonmark.commonmark(str(result['nutritional_info']))\n",
    "    else:\n",
    "      rnutrition = None\n",
    "\n",
    "    result['html'] = {\n",
    "      'directions'  : rdirections,\n",
    "      'description' : rdescription,\n",
    "      'ingredients' : ringredients,\n",
    "      'nutrition'   : rnutrition\n",
    "      }\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Categories\n",
    "    # Split concatened categories into a list\n",
    "    if key == \"categories\":\n",
    "        try:\n",
    "            result['categories'] = value.split('|')\n",
    "            for cl in result['categories']:\n",
    "              #catss = {make_filename(result['name']):str(result['name']}\n",
    "              #catss_copy = catss.copy()\n",
    "              #cats[ck].append(catss_copy)\n",
    "              #cats[ck][make_filename(result['name'])] = str(result['name'])\n",
    "              \n",
    "              # Using the categories as a toggle hack (by Joi or not)\n",
    "              if cl == \"_mine\":\n",
    "                result['type'] = cl\n",
    "\n",
    "              if cl not in cats.keys():\n",
    "                cats[cl] = {}\n",
    "\n",
    "              if fileName not in cats[cl].keys():\n",
    "                cats[cl][fileName] = str(result['name'])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Sources\n",
    "    if result[\"source\"] == \"\":\n",
    "        result[\"source\"] = None \n",
    "    if result[\"source_url\"] == \"\":\n",
    "        result[\"source_url\"] = None \n",
    "\n",
    "    # end of RESULT Items FOR loop }\n",
    "    # --------------------------------------------------------------------------------------\n",
    "  \n",
    "\n",
    "    # --------------------------------------------------------------------------------------\n",
    "    # Temporary, parse out the name:filename dictionary into a list of key:value dicts\n",
    "    # I am doing this to preserve legacy in the Jekyl templates. May remove laters.\n",
    "    for k,v in sorted(result['photos_dict'].items()):\n",
    "        phots = {'filename':v,'name':k}\n",
    "        result['photos'].append(phots)\n",
    "    # Delete the concatened phot_names and photo_filenames string we got from the SQL query\n",
    "    del result['photos_names'],result['photos_filenames']\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    # Convert the data struct to JSON and dump it to individual files\n",
    "    json_dump = json.dumps(result, ensure_ascii=False, sort_keys=True, indent=2)\n",
    "    jsonFilePath = path_output_json_files + fileName + \".json\"\n",
    "    f = open(jsonFilePath, 'w')\n",
    "    f.write(json_dump)\n",
    "    f.close()\n",
    "\n",
    "    # Prepare and Dump the Markodwn Recipe Stub Files\n",
    "    # MARKDOWN --------------------------------\n",
    "    # Create a string of Markdown\n",
    "    # So this will require some \"design.\" What do we want to include from the export?\n",
    "    # How should it be styled? What do we jam into the metadata/frontmatter\n",
    "    # What do we include as #tags in the body?\n",
    "\n",
    "    output  = \"---\\n\"\n",
    "    output += \"title: \\\"\" + result['name'] + \"\\\"\\n\"\n",
    "    output += \"filename: \\\"\" + fileName + \"\\\"\\n\"\n",
    "    output += \"created: \" + str(result['created']) + \"\\n\"\n",
    "    output += \"---\\n\"\n",
    "    if (result['notes']):\n",
    "      output += str(result['notes']) + \"\\n\"\n",
    "    \n",
    "    # Create/Open a text file for each recipe and write the above Markdown string into it\n",
    "    mdFilePath = path_output_mkdn_files + fileName + \".md\"\n",
    "    f = open(mdFilePath, 'w')\n",
    "    f.write(output)\n",
    "    f.close()\n",
    "    \n",
    "# CLOSE DB\n",
    "conn.close()\n",
    "\n",
    "\n",
    "# Convert the data struct to JSON and dump it to individual files\n",
    "json_cats_dump = json.dumps(cats, ensure_ascii=False, sort_keys=True, indent=2)\n",
    "jsonDataPath = path_output_json_data + \"recipe_categories.json\"\n",
    "f = open(jsonDataPath, 'w')\n",
    "f.write(json_cats_dump)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# End of Main RESULTS FOR Loop }\n",
    "    \n",
    "#pp = pprint.PrettyPrinter(indent=4)\n",
    "#pp.pprint(cats)\n",
    "#print(cats)\n",
    "\n",
    "# CLEANUP --------------------------------------------\n",
    "# Delete the temp working direcotry\n",
    "shutil.rmtree(path_temp_working, ignore_errors=True) # \"ignore errors\" nukes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES ----------------------------------------------\n",
    "# Move the images out of the unzipped My Recipes dir to somehwere Jekyll can pick them up.\n",
    "\n",
    "if os.path.exists(path_output_phot_files):\n",
    "    shutil.rmtree(path_output_phot_files, ignore_errors=True)\n",
    "    #print(\"Nuked Recipe / Images Directory\")\n",
    "\n",
    "moveReturn = shutil.copytree(path_photos, path_output_phot_files)\n",
    "#print(\"Successfully copied to destination path:\", moveReturn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DONE!\n",
    "👍🏼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}